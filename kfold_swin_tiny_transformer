{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define transformations\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BICUBIC),  # High-quality resize\n    transforms.RandomHorizontalFlip(p=0.5),  # Augmentation\n    transforms.RandomRotation(15),  # Â±15 degrees\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Reduce lighting bias\n    transforms.ToTensor(),  # Convert to tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BICUBIC),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Load dataset (for exploration)\ndataset = ImageFolder(root='data', transform=val_transform)  # No augmentation for initial check\n\n# Explore dataset\nprint(f\"Total images: {len(dataset)}\")\nclass_counts = dict.fromkeys(dataset.classes, 0)\nfor _, label in dataset.samples:\n    class_counts[dataset.classes[label]] += 1\nprint(f\"Class distribution: {class_counts}\")\n\n# Visualize a few samples\ndef show_images(dataset, num_samples=4):\n    loader = DataLoader(dataset, batch_size=num_samples, shuffle=True)\n    images, labels = next(iter(loader))\n    images = images.numpy().transpose((0, 2, 3, 1))  # [B, C, H, W] -> [B, H, W, C]\n    images = images * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])  # Denormalize\n    images = np.clip(images, 0, 1)\n    \n    plt.figure(figsize=(12, 3))\n    for i in range(num_samples):\n        plt.subplot(1, num_samples, i+1)\n        plt.imshow(images[i])\n        plt.title(dataset.classes[labels[i]])\n        plt.axis('off')\n    plt.show()\n\nshow_images(dataset)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}