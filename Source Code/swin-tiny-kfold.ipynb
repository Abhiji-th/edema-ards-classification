{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11040779,"sourceType":"datasetVersion","datasetId":6877214},{"sourceId":11155876,"sourceType":"datasetVersion","datasetId":6960425}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom PIL import Image\nimport numpy as np\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nfrom transformers import SwinModel, SwinConfig\n\n# Custom Dataset Class\nclass CovidPneumoniaDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.classes = ['covid', 'pneumonia']\n        self.images = []\n        self.labels = []\n        \n        for label, class_name in enumerate(self.classes):\n            class_dir = os.path.join(root_dir, class_name)\n            if os.path.exists(class_dir):\n                for img_name in os.listdir(class_dir):\n                    img_path = os.path.join(class_dir, img_name)\n                    self.images.append(img_path)\n                    self.labels.append(label)\n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        img_path = self.images[idx]\n        label = self.labels[idx]\n        \n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n            \n        return image, label\n\n# Custom Model with Swin Tiny Transformer\nclass SwinBinaryClassifier(nn.Module):\n    def __init__(self):\n        super(SwinBinaryClassifier, self).__init__()\n        self.swin = SwinModel.from_pretrained('microsoft/swin-tiny-patch4-window7-224')\n        self.head = nn.Sequential(\n            nn.Linear(768, 256),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, 2)\n        )\n    \n    def forward_features(self, x):\n        return self.swin(x).last_hidden_state[:, 0, :]\n    \n    def forward(self, x):\n        features = self.forward_features(x)\n        return self.head(features)\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Data transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                        std=[0.229, 0.224, 0.225])\n])\n\n# Load full dataset\ndata_dir = \"/kaggle/input/covid-pneumonia-lus-images/covid_pneumonia\"  # Replace with your dataset path containing covid/ and pneumonia/ folders\nfull_dataset = CovidPneumoniaDataset(root_dir=data_dir, transform=transform)\n\n# Perform train-test split\ntrain_idx, test_idx = train_test_split(\n    range(len(full_dataset)),\n    test_size=0.2,  # 20% for test set\n    stratify=full_dataset.labels,  # Maintain class distribution\n    random_state=42\n)\n\ntrain_dataset = Subset(full_dataset, train_idx)\ntest_dataset = Subset(full_dataset, test_idx)\n\n# Cross-validation parameters\nn_splits = 5\nnum_epochs = 5\nbatch_size = 16\nkfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n# Training and validation loop for hyperparameter tuning\nfold_val_accs = []\nfold_val_f1s = []\n\nfor fold, (train_idx_cv, val_idx_cv) in enumerate(kfold.split(range(len(train_dataset)))):\n    print(f'\\nFold {fold + 1}/{n_splits}')\n    \n    # Create train and validation subsets from training data\n    train_subset = Subset(train_dataset, train_idx_cv)\n    val_subset = Subset(train_dataset, val_idx_cv)\n    \n    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n    \n    model = SwinBinaryClassifier().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=2e-5)\n    criterion = nn.CrossEntropyLoss()\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n    \n    # Training loop\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        train_preds, train_labels = [], []\n        \n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            train_preds.extend(predicted.cpu().numpy())\n            train_labels.extend(labels.cpu().numpy())\n        \n        train_acc = accuracy_score(train_labels, train_preds) * 100\n        avg_loss = running_loss / len(train_loader)\n        \n        # Validation\n        model.eval()\n        val_preds, val_labels = [], []\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                val_preds.extend(predicted.cpu().numpy())\n                val_labels.extend(labels.cpu().numpy())\n        \n        val_acc = accuracy_score(val_labels, val_preds) * 100\n        val_f1 = f1_score(val_labels, val_preds, average='binary')\n        \n        print(f'Epoch {epoch+1}/{num_epochs}:')\n        print(f'Train Loss: {avg_loss:.4f}, Train Acc: {train_acc:.2f}%')\n        print(f'Val Acc: {val_acc:.2f}%, Val F1: {val_f1:.4f}')\n        \n        scheduler.step()\n    \n    fold_val_accs.append(val_acc)\n    fold_val_f1s.append(val_f1)\n\n# Cross-validation results\nprint('\\nCross-validation Results:')\nprint(f'Average Val Accuracy: {np.mean(fold_val_accs):.2f}% (±{np.std(fold_val_accs):.2f})')\nprint(f'Average Val F1 Score: {np.mean(fold_val_f1s):.4f} (±{np.std(fold_val_f1s):.4f})')\n\n# Train final model on full training set\nprint('\\nTraining final model on full training set...')\nfinal_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nfinal_model = SwinBinaryClassifier().to(device)\noptimizer = optim.Adam(final_model.parameters(), lr=2e-5)\ncriterion = nn.CrossEntropyLoss()\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\nfor epoch in range(num_epochs):\n    final_model.train()\n    running_loss = 0.0\n    train_preds, train_labels = [], []\n    \n    for images, labels in final_train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = final_model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        train_preds.extend(predicted.cpu().numpy())\n        train_labels.extend(labels.cpu().numpy())\n    \n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    avg_loss = running_loss / len(final_train_loader)\n    print(f'Epoch {epoch+1}/{num_epochs}: Train Loss: {avg_loss:.4f}, Train Acc: {train_acc:.2f}%')\n    scheduler.step()\n\n# Evaluate on test set\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\nfinal_model.eval()\ntest_preds, test_labels = [], []\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = final_model(images)\n        _, predicted = torch.max(outputs, 1)\n        test_preds.extend(predicted.cpu().numpy())\n        test_labels.extend(labels.cpu().numpy())\n\ntest_acc = accuracy_score(test_labels, test_preds) * 100\ntest_f1 = f1_score(test_labels, test_preds, average='binary')\ncm = confusion_matrix(test_labels, test_preds)\n\nprint('\\nFinal Test Set Results:')\nprint(f'Test Accuracy: {test_acc:.2f}%')\nprint(f'Test F1 Score: {test_f1:.4f}')\nprint('Confusion Matrix:')\nprint(cm)\nprint(\"Training and evaluation complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T16:23:54.541282Z","iopub.execute_input":"2025-04-12T16:23:54.541486Z","iopub.status.idle":"2025-04-12T16:31:28.625991Z","shell.execute_reply.started":"2025-04-12T16:23:54.541466Z","shell.execute_reply":"2025-04-12T16:31:28.624953Z"}},"outputs":[{"name":"stdout","text":"\nFold 1/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/71.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8940833733e049d0ad56a573d7dfd76e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/113M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"260e949039dd40c89a4569430174c9c5"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/5:\nTrain Loss: 0.3972, Train Acc: 84.94%\nVal Acc: 89.87%, Val F1: 0.9000\nEpoch 2/5:\nTrain Loss: 0.1762, Train Acc: 92.55%\nVal Acc: 91.77%, Val F1: 0.9182\nEpoch 3/5:\nTrain Loss: 0.0800, Train Acc: 96.83%\nVal Acc: 91.77%, Val F1: 0.9182\nEpoch 4/5:\nTrain Loss: 0.0695, Train Acc: 96.67%\nVal Acc: 91.77%, Val F1: 0.9182\nEpoch 5/5:\nTrain Loss: 0.0662, Train Acc: 97.15%\nVal Acc: 91.77%, Val F1: 0.9182\n\nFold 2/5\nEpoch 1/5:\nTrain Loss: 0.5219, Train Acc: 75.28%\nVal Acc: 90.51%, Val F1: 0.9020\nEpoch 2/5:\nTrain Loss: 0.1469, Train Acc: 94.45%\nVal Acc: 99.37%, Val F1: 0.9937\nEpoch 3/5:\nTrain Loss: 0.0721, Train Acc: 98.26%\nVal Acc: 100.00%, Val F1: 1.0000\nEpoch 4/5:\nTrain Loss: 0.0523, Train Acc: 99.05%\nVal Acc: 100.00%, Val F1: 1.0000\nEpoch 5/5:\nTrain Loss: 0.0459, Train Acc: 99.68%\nVal Acc: 100.00%, Val F1: 1.0000\n\nFold 3/5\nEpoch 1/5:\nTrain Loss: 0.4845, Train Acc: 76.23%\nVal Acc: 93.67%, Val F1: 0.9359\nEpoch 2/5:\nTrain Loss: 0.1557, Train Acc: 95.25%\nVal Acc: 100.00%, Val F1: 1.0000\nEpoch 3/5:\nTrain Loss: 0.0514, Train Acc: 98.89%\nVal Acc: 100.00%, Val F1: 1.0000\nEpoch 4/5:\nTrain Loss: 0.0457, Train Acc: 99.05%\nVal Acc: 100.00%, Val F1: 1.0000\nEpoch 5/5:\nTrain Loss: 0.0422, Train Acc: 99.21%\nVal Acc: 100.00%, Val F1: 1.0000\n\nFold 4/5\nEpoch 1/5:\nTrain Loss: 0.4961, Train Acc: 75.12%\nVal Acc: 87.34%, Val F1: 0.8361\nEpoch 2/5:\nTrain Loss: 0.1594, Train Acc: 93.34%\nVal Acc: 98.10%, Val F1: 0.9778\nEpoch 3/5:\nTrain Loss: 0.0734, Train Acc: 98.73%\nVal Acc: 98.10%, Val F1: 0.9778\nEpoch 4/5:\nTrain Loss: 0.0588, Train Acc: 99.05%\nVal Acc: 98.73%, Val F1: 0.9851\nEpoch 5/5:\nTrain Loss: 0.0534, Train Acc: 99.21%\nVal Acc: 98.73%, Val F1: 0.9851\n\nFold 5/5\nEpoch 1/5:\nTrain Loss: 0.4699, Train Acc: 81.80%\nVal Acc: 85.99%, Val F1: 0.8571\nEpoch 2/5:\nTrain Loss: 0.2325, Train Acc: 89.08%\nVal Acc: 94.90%, Val F1: 0.9452\nEpoch 3/5:\nTrain Loss: 0.1134, Train Acc: 96.20%\nVal Acc: 94.90%, Val F1: 0.9452\nEpoch 4/5:\nTrain Loss: 0.0958, Train Acc: 97.15%\nVal Acc: 94.90%, Val F1: 0.9452\nEpoch 5/5:\nTrain Loss: 0.0894, Train Acc: 97.47%\nVal Acc: 94.90%, Val F1: 0.9452\n\nCross-validation Results:\nAverage Val Accuracy: 97.08% (±3.25)\nAverage Val F1 Score: 0.9697 (±0.0326)\n\nTraining final model on full training set...\nEpoch 1/5: Train Loss: 0.4885, Train Acc: 76.17%\nEpoch 2/5: Train Loss: 0.0987, Train Acc: 97.97%\nEpoch 3/5: Train Loss: 0.0350, Train Acc: 99.24%\nEpoch 4/5: Train Loss: 0.0344, Train Acc: 99.49%\nEpoch 5/5: Train Loss: 0.0356, Train Acc: 99.11%\n\nFinal Test Set Results:\nTest Accuracy: 99.49%\nTest F1 Score: 0.9947\nConfusion Matrix:\n[[104   1]\n [  0  93]]\nTraining and evaluation complete!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nlabels = ['covid', 'pneumonia']\nclass_report = classification_report(test_labels, test_preds, target_names=labels)\nprint(class_report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T16:56:31.789497Z","iopub.execute_input":"2025-04-12T16:56:31.789832Z","iopub.status.idle":"2025-04-12T16:56:31.803513Z","shell.execute_reply.started":"2025-04-12T16:56:31.789803Z","shell.execute_reply":"2025-04-12T16:56:31.802682Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n       covid       1.00      0.99      1.00       105\n   pneumonia       0.99      1.00      0.99        93\n\n    accuracy                           0.99       198\n   macro avg       0.99      1.00      0.99       198\nweighted avg       1.00      0.99      0.99       198\n\n","output_type":"stream"}],"execution_count":6}]}